{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10bd8cf0-6dec-4b55-af4c-906bda44c873",
   "metadata": {},
   "source": [
    "Group and sum by metaprogram problem solved with: https://stackoverflow.com/questions/39650749/group-by-sparse-matrix-in-scipy-and-return-a-matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218c8ba1-ac5a-4c9d-861c-b29fc87813e1",
   "metadata": {},
   "source": [
    "#### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bbf62c-43e3-4d75-91c3-70e6f8b400fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b1d5f32-0a5f-4149-ad2d-b678070167f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = '/n/scratch/users/s/sad167/EPN/Xenium/'\n",
    "directory = base_directory + 'analysis/7_neighborhoods'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcb11c3-15a4-4e1e-99eb-a3901a6b0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import metadata\n",
    "metadata = pd.read_excel(base_directory+'scripts_revisions/SampleIdentifier.xlsx')\n",
    "\n",
    "# extract sample name and path to raw data\n",
    "SampleName = metadata['SampleName'].tolist()\n",
    "SampleID = metadata['Sample'].tolist()\n",
    "RawDataPath = metadata['RawDataPath'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2750d23-0b57-490a-af3c-2f03e201e3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEPN17_Region_1\n",
      "STEPN06_Region_1\n",
      "STEPN06_Region_2\n",
      "STEPN06_Region_3\n",
      "STEPN10_Region_1\n",
      "STEPN10_Region_2\n",
      "STEPN12_Region_1\n",
      "STEPN12_Region_2\n",
      "STEPN12_Region_3\n",
      "STEPN14_Region_1\n",
      "STEPN14_Region_2\n",
      "STEPN19_Region_1\n",
      "STEPN19_Region_2\n",
      "STEPN16_Region_1\n",
      "STEPN18_Region_1\n",
      "STEPN01_Region_1\n",
      "STEPN01_Region_2\n",
      "STEPN01_Region_3\n",
      "STEPN06_Region_4\n",
      "STEPN06_Region_5\n",
      "STEPN10_Region_3\n",
      "STEPN12_Region_4\n",
      "STEPN15_Region_1\n"
     ]
    }
   ],
   "source": [
    "# color palette\n",
    "metaprogram_names = [\"Neuroepithelial-like\", \"Radial-glia-like\", \n",
    "                                       \"Embryonic-neuronal-like\", \"Neuronal-like\" ,\"Ependymal-like\", \"MES-like\", \n",
    "                                       \"T-cells\", \"Myeloid\",  \"Endothelial\",  \"Oligodendrocytes\", 'Astrocyte', 'Neurons']\n",
    "\n",
    "metaprogram_colors = [\"#F99E93FF\",\"#9E5E9BFF\",\"#74ADD1FF\",'#0F4F8B', \"#ACD39EFF\",\"#96410EFF\", \n",
    "                                '#FFF087FF',  '#F47942FF', 'violetred3', '#AECEBFFF', '#30A0A4FF', '#55A19EFF']\n",
    "\n",
    "metaprogram_to_color = dict(zip(metaprogram_names, metaprogram_colors))\n",
    "\n",
    "anndata_list = []\n",
    "for i in range(len(SampleName)):\n",
    "    adata = sc.read_10x_h5(filename = base_directory + 'data/raw_data/' + RawDataPath[i]+'/cell_feature_matrix.h5')\n",
    "    df = pd.read_csv(base_directory + 'data/raw_data/' + RawDataPath[i]+'/cells.csv.gz')\n",
    "\n",
    "    df.set_index(adata.obs_names, inplace=True)\n",
    "    adata.obs = df.copy()\n",
    "\n",
    "    adata.obsm[\"spatial\"] = np.array([adata.obs.x_centroid*0.325, adata.obs.y_centroid*0.325]).transpose().astype('float64')\n",
    "    \n",
    "    # read metadata with annotations\n",
    "    anno = pd.read_csv(base_directory + 'analysis/3_program_annotation/data/cell_ID_'  + SampleName[i] + '.csv', index_col = 0)\n",
    "\n",
    "    # Replace values in the \"group\" column\n",
    "    anno['group'].replace({'Embryonic-like': 'Neuroepithelial-like'}, inplace=True)\n",
    "\n",
    "    if 'X' in anno.columns:\n",
    "        anno.index = anno['X']\n",
    "    \n",
    "    adata = adata[anno.index,:]\n",
    "    \n",
    "    adata.obs['Metaprogram'] = anno['group']\n",
    "    adata.obs['Metaprogram'] = adata.obs['Metaprogram'].astype('category')\n",
    "    adata.obs['sample'] = SampleName[i]\n",
    "    adata.obs['SampleID'] = SampleID[i]\n",
    "    \n",
    "    # Add the color information to the AnnData object\n",
    "    adata.uns['Metaprogram_colors'] = metaprogram_to_color\n",
    "    \n",
    "    anndata_list.append(adata)\n",
    "    \n",
    "    print(SampleName[i])\n",
    "\n",
    "adata = sc.concat(anndata_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34d9146b-7d21-4457-a1fa-b2e996de98e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to remove \"Unassigned\" program \n",
    "adata = adata[~adata.obs['Metaprogram'].isin(['Unknown'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62fa485-8040-45f8-9be1-cbada8f1dc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEPN17_Region_1\n"
     ]
    }
   ],
   "source": [
    "ad = adata\n",
    "\n",
    "anndata_list = []\n",
    "for sample in ad.obs['sample'].unique():\n",
    "    adata_copy_int = ad[ad.obs['sample'] == sample ]\n",
    "    adata_copy_int.obs.index = list(pd.DataFrame(list((adata_copy_int.obs['sample'])))[0] +'_' +pd.DataFrame(list((adata_copy_int.obs.index)))[0])\n",
    "    sq.gr.spatial_neighbors(adata_copy_int, coord_type = 'generic', radius = 70.0)\n",
    "    \n",
    "    if len(adata_copy_int.obs.groupby('Metaprogram').size()) == 2:\n",
    "        datf = pd.DataFrame(data = scipy.sparse.csr_matrix.todense((adata_copy_int.obsp['spatial_distances']>0)*1))\n",
    "        datf['key'] = list(adata_copy_int.obs['Metaprogram'])\n",
    "        neighmatrix = datf.groupby('key').sum().transpose()\n",
    "    else:\n",
    "        lb = LabelBinarizer(sparse_output=True)\n",
    "        grouped = lb.fit_transform(adata_copy_int.obs['Metaprogram'].to_numpy()).T.dot((adata_copy_int.obsp['spatial_distances']>0)*1)\n",
    "        neighmatrix = pd.DataFrame(data = scipy.sparse.csr_matrix.todense(grouped)).transpose()\n",
    "        neighmatrix.set_axis(sorted(adata_copy_int.obs['Metaprogram'].unique()), axis = \"columns\", copy = False)\n",
    "    \n",
    "    adataneigh = sc.AnnData(neighmatrix)\n",
    "    adataneigh.obs = adata_copy_int.obs\n",
    "    adataneigh.obs['counts'] = list(np.sum(neighmatrix,axis=1))\n",
    "    anndata_list.append(adataneigh)\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3411c5b-6d56-4cdd-ae45-77f5617b531b",
   "metadata": {},
   "source": [
    "#### Compute centrality scores per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71c1c1-99a4-46bc-a8ba-9a35b41bb220",
   "metadata": {},
   "outputs": [],
   "source": [
    "centralityScore_list = []\n",
    "for i in range(len(anndata_list)):\n",
    "    anndata_list[i].obsm[\"spatial\"] = np.array([anndata_list[i].obs.x_centroid*0.325, anndata_list[i].obs.y_centroid*0.325]).transpose().astype('float64')\n",
    "    anndata_list[i].X = np.nan_to_num(anndata_list[i].X)\n",
    "    anndata_list[i] = anndata_list[i][anndata_list[i].obs['counts'] > 6]\n",
    "    anndata_list[i].raw = anndata_list[i]\n",
    "    \n",
    "    sq.gr.spatial_neighbors(anndata_list[i], coord_type = \"generic\", delaunay = True)\n",
    "    sq.gr.centrality_scores(anndata_list[i], cluster_key = \"Metaprogram\")\n",
    "\n",
    "    dt = anndata_list[i].uns['Metaprogram_centrality_scores']\n",
    "    dt['Metaprogram'] = dt.index\n",
    "    dt['Sample'] = SampleName[i]\n",
    "    \n",
    "    centralityScore_list.append(dt)\n",
    "    print(SampleName[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f969c2b7-c097-442a-9c3f-cdb58360a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate scores\n",
    "dt = pd.concat(centralityScore_list)\n",
    "## Calculated average and SEM first by sample (to avoid that technical replicates have too much weight)\n",
    "dt = dt.groupby(['Metaprogram', 'SampleID'], as_index=False).agg({\n",
    "    'degree_centrality': ['mean'],\n",
    "    'average_clustering': ['mean'],\n",
    "    'closeness_centrality': ['mean']\n",
    "})\n",
    "dt.columns = ['Metaprogram', 'Sample',\n",
    "              'degree_centrality', 'average_clustering', 'closeness_centrality']\n",
    "## Now calculate average by metaprogram\n",
    "dt = dt.groupby(['Metaprogram'], as_index=False).agg({\n",
    "    'degree_centrality': ['mean', 'sem'],\n",
    "    'average_clustering': ['mean', 'sem'],\n",
    "    'closeness_centrality': ['mean', 'sem']\n",
    "})\n",
    "\n",
    "dt.columns = ['Metaprogram', \n",
    "              'degree_centrality_mean', 'degree_centrality_sem', \n",
    "              'average_clustering_mean', 'average_clustering_sem', \n",
    "              'closeness_centrality_mean', 'closeness_centrality_sem']\n",
    "\n",
    "\n",
    "# remove unknown\n",
    "dt = dt[~dt['Metaprogram'].str.contains('Unknown', case=False, na=False)]\n",
    "\n",
    "\n",
    "## Scatter plot with error bars\n",
    "plt.figure(figsize=(5, 5))\n",
    "pt = sns.scatterplot(data=dt, x=\"average_clustering_mean\", y=\"degree_centrality_mean\", hue=\"Metaprogram\", \n",
    "                     palette=metaprogram_to_color, \n",
    "                     legend = True, s = 100)\n",
    "for i, row in dt.iterrows():\n",
    "    plt.errorbar(x=row['average_clustering_mean'], y=row['degree_centrality_mean'], \n",
    "                  xerr=row['average_clustering_sem'], yerr=row['degree_centrality_sem'], \n",
    "                 fmt='o', capsize=5, color=metaprogram_to_color[row['Metaprogram']]\n",
    "                )\n",
    "\n",
    "\n",
    "pt.set(xlabel = 'Clustering coefficient', ylabel = 'Degree of centrality')\n",
    "pt.legend(fontsize = 6)\n",
    "plt.savefig(directory+f\"/1_centrality_scores_averages.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48cadf-3d1e-46c3-b9da-55a481cfb7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate neighborhood\n",
    "nhood_list = []\n",
    "for i in range(len(anndata_list)):\n",
    "    sq.gr.nhood_enrichment(anndata_list[i], cluster_key = \"Metaprogram\", seed = 1234)\n",
    "    \n",
    "    df = pd.DataFrame(anndata_list[i].uns['Metaprogram_nhood_enrichment']['zscore'])\n",
    "    df.index = anndata_list[i].uns['Metaprogram_centrality_scores'].index\n",
    "    df.columns = anndata_list[i].uns['Metaprogram_centrality_scores'].index\n",
    "    df['Programs'] = anndata_list[i].uns['Metaprogram_centrality_scores'].index\n",
    "\n",
    "    df = pd.melt(df, id_vars='Programs')\n",
    "    df['Sample'] = anndata_list[i].uns['Metaprogram_centrality_scores']['Sample'].unique()[0]\n",
    "    df['SampleID'] = anndata_list[i].uns['Metaprogram_centrality_scores']['SampleID'].unique()[0]\n",
    "\n",
    "    nhood_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b8851c-a1ef-4ecd-ac87-16c48117e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as dataframes\n",
    "concatenated_df = pd.concat(nhood_list, ignore_index=True)\n",
    "concatenated_df.to_csv(directory+f'/2_neighborhood.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0c9bb-75a5-48ad-a7d6-38db28e2fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Averaging metrics\n",
    "dt = pd.concat(nhood_list)\n",
    "dt = dt.groupby(['Programs', 'variable'], as_index=False).agg({'value': 'mean'})\n",
    "dt = dt.pivot(index='Programs', columns='variable')['value']\n",
    "dt.to_csv(directory+f'/2_neighborhood_average.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13729d78-dc05-4e0c-978f-cec706eb189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
